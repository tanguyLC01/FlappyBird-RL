{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-25T16:09:34.432296Z",
     "iopub.status.busy": "2025-03-25T16:09:34.431880Z",
     "iopub.status.idle": "2025-03-25T16:09:38.071114Z",
     "shell.execute_reply": "2025-03-25T16:09:38.070031Z",
     "shell.execute_reply.started": "2025-03-25T16:09:34.432265Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.0->gymnasium) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.0->gymnasium) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.0->gymnasium) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.0->gymnasium) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.0->gymnasium) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import flappy_bird_gymnasium\n",
    "import gymnasium\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T16:09:43.387290Z",
     "iopub.status.busy": "2025-03-25T16:09:43.386874Z",
     "iopub.status.idle": "2025-03-25T16:09:46.888771Z",
     "shell.execute_reply": "2025-03-25T16:09:46.887690Z",
     "shell.execute_reply.started": "2025-03-25T16:09:43.387267Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flappy-bird-gymnasium in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
      "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (from flappy-bird-gymnasium) (0.29.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from flappy-bird-gymnasium) (1.26.4)\n",
      "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from flappy-bird-gymnasium) (2.6.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from flappy-bird-gymnasium) (3.7.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->flappy-bird-gymnasium) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->flappy-bird-gymnasium) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium->flappy-bird-gymnasium) (0.0.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->flappy-bird-gymnasium) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->flappy-bird-gymnasium) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->flappy-bird-gymnasium) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->flappy-bird-gymnasium) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->flappy-bird-gymnasium) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->flappy-bird-gymnasium) (2.4.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->flappy-bird-gymnasium) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->flappy-bird-gymnasium) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->flappy-bird-gymnasium) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->flappy-bird-gymnasium) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->flappy-bird-gymnasium) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->flappy-bird-gymnasium) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install flappy-bird-gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T16:09:46.890595Z",
     "iopub.status.busy": "2025-03-25T16:09:46.890328Z",
     "iopub.status.idle": "2025-03-25T16:09:50.390482Z",
     "shell.execute_reply": "2025-03-25T16:09:50.389547Z",
     "shell.execute_reply.started": "2025-03-25T16:09:46.890573Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.0->gymnasium) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.0->gymnasium) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.0->gymnasium) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.0->gymnasium) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.0->gymnasium) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DQN(torch.nn.Module):\n",
    "    def __init__(self, action_space):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.fc1 = nn.Linear(6 * 6 * 64, 512)\n",
    "        self.fc2 = nn.Linear(512, action_space)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, observation):\n",
    "        output = self.relu(self.conv1(observation))\n",
    "        output = self.relu(self.conv2(output))\n",
    "        output = self.relu(self.conv3(output))\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.relu(self.fc1(output))\n",
    "        output = self.fc2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T16:09:50.400182Z",
     "iopub.status.busy": "2025-03-25T16:09:50.399893Z",
     "iopub.status.idle": "2025-03-25T16:09:50.420910Z",
     "shell.execute_reply": "2025-03-25T16:09:50.420066Z",
     "shell.execute_reply.started": "2025-03-25T16:09:50.400143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import torch.optim as optim\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    \n",
    "    def __init__(self, parameters):\n",
    "        self.eps_decay = parameters['eps_decay']\n",
    "        self.eps_min = parameters['eps_min']\n",
    "        self.eps = parameters['eps_start']\n",
    "        self.action_space = parameters['action_space']\n",
    "        self.memory = deque(maxlen=parameters['memory_size'])\n",
    "        self.pre_trained_episode = parameters['pre_train_steps']\n",
    "        self.device = parameters['device']\n",
    "        self.batch_size = parameters['batch_size']\n",
    "        self.gamma = parameters['gamma']\n",
    "        self.num_episodes = parameters['num_episodes']\n",
    "        self.Q_policy = DQN(self.action_space).to(self.device)\n",
    "        self.Q_target = copy.deepcopy(self.Q_policy).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.Q_policy.parameters(), lr=parameters['learning_rate'])\n",
    "        self.lossFuc = nn.MSELoss()\n",
    "        self.action_dict = {0: 0, 1: 1}\n",
    "    \n",
    "    def one_hot_embedding(self, labels, num_classes):\n",
    "        y = torch.eye(num_classes) \n",
    "        return y[labels] \n",
    "    \n",
    "    def img_process(self, img):\n",
    "        img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "        img = cv2.flip(img, 1)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (80, 80))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        _, img = cv2.threshold(img, 50, 255, cv2.THRESH_BINARY)\n",
    "        return img\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def predict(self, state):\n",
    "        state = np.reshape(state, (1, 1, 80, 80))\n",
    "        state_tensor = torch.FloatTensor(state).to(self.device)\n",
    "        q_values = self.Q_policy(state_tensor)[0]\n",
    "\n",
    "        if np.random.rand() < self.eps:\n",
    "            max_q_index = [random.randrange(self.action_space)]\n",
    "            max_q_one_hot = self.one_hot_embedding(max_q_index, self.action_space)\n",
    "        else:\n",
    "            max_q_index = [torch.max(q_values, 0).indices.cpu().numpy().tolist()]\n",
    "            max_q_one_hot = self.one_hot_embedding(max_q_index, self.action_space)\n",
    "        return max_q_index, max_q_one_hot.to(self.device), q_values\n",
    "\n",
    "    def experience_replay(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        batch = random.sample(self.memory, self.batch_size)\n",
    "        state_batch, action_batch, reward_batch, next_state_batch, terminal_batch = zip(*batch)\n",
    "        state_batch = torch.cat([torch.FloatTensor(s) for s in state_batch]).reshape(-1, 1, 80, 80).to(self.device)\n",
    "        action_batch = torch.stack(action_batch).reshape(-1, self.action_space)\n",
    "        reward_batch = torch.cat([torch.FloatTensor([r]) for r in reward_batch]).to(self.device).reshape(-1, 1)\n",
    "        next_state_batch = torch.cat([torch.FloatTensor(s) for s in next_state_batch]).to(self.device).reshape(-1, 1, 80, 80)\n",
    "\n",
    "        #terminal = torch.cat([torch.tensor(t, dtype=torch.float32) for t in terminal_batch])\n",
    "        current_predictions = self.Q_policy(state_batch)\n",
    "        next_predictions = self.Q_target(next_state_batch)\n",
    "        y_batch = torch.cat([\n",
    "            r if d else r + self.gamma * torch.max(p)\n",
    "            for r, d, p in zip(reward_batch, terminal_batch, next_predictions)\n",
    "        ]).to(self.device)\n",
    "\n",
    "        q_value = torch.sum(current_predictions * action_batch, dim=1)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.lossFuc(q_value, y_batch)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        self.eps = max(self.eps_min, self.eps_decay * self.eps)\n",
    "    \n",
    "    def save_model(self, file_name='dqn_model.pth'):\n",
    "        checkpoint = {\n",
    "            'model_state_dict': self.Q_policy.state_dict(),\n",
    "            'target_model_state_dict': self.Q_target.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'eps': self.eps,\n",
    "        }\n",
    "        torch.save(checkpoint, file_name)\n",
    "        print(f\"Model saved to {file_name}\")\n",
    "    \n",
    "    def load_model(self, file_name='dqn_model.pth'):\n",
    "        checkpoint = torch.load(file_name)\n",
    "        self.Q_policy.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.Q_target.load_state_dict(checkpoint['target_model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.eps = checkpoint['eps']\n",
    "        print(f\"Model loaded from {file_name}\")\n",
    "    \n",
    "    def train(self, env):\n",
    "        run = 0\n",
    "        score_values = []\n",
    "        q_values = []\n",
    "        rewards_total = []\n",
    "        best_reward = float(\"-inf\")\n",
    "        with open('training_log.txt', 'w') as f:\n",
    "            for _ in range(self.num_episodes):\n",
    "                episode_reward = 0.0\n",
    "                run += 1\n",
    "                state = env.reset()\n",
    "                state = env.render()\n",
    "                state = self.img_process(state)\n",
    "                step = 0\n",
    "\n",
    "                if run % 5000 == 4999:\n",
    "                    self.save_model('model_checkpoint.pth')\n",
    "\n",
    "                done = False\n",
    "                \n",
    "                while not done:\n",
    "                    step += 1\n",
    "                    action, action_one_hot, p_values = self.predict(state)\n",
    "                    next_state, reward, done, info, score = env.step(self.action_dict[action[0]])\n",
    "                    next_state = env.render()\n",
    "                    next_state = self.img_process(next_state)\n",
    "                    reward = torch.tensor([reward], device=self.device)\n",
    "                    self.remember(state, action_one_hot, reward, next_state, done)\n",
    "                    episode_reward += reward.detach().cpu().numpy()[0]\n",
    "                    state = next_state\n",
    "\n",
    "                    if done:\n",
    "                        log = f\"Run: {run}, exploration: {self.eps}, score: {score['score']}, Q_value: {torch.max(p_values)}, Reward : {episode_reward}\"\n",
    "                        print(log)\n",
    "                        f.write(log + '\\n')\n",
    "                        q_values.append(torch.max(p_values))\n",
    "                        score_values.append(score['score'])\n",
    "                        rewards_total.append(episode_reward)\n",
    "                        break\n",
    "\n",
    "                    self.experience_replay()\n",
    "\n",
    "                    if step % 50 == 0:\n",
    "                        self.Q_target.load_state_dict(copy.deepcopy(self.Q_policy.state_dict()))\n",
    "                        \n",
    "                if episode_reward > best_reward:\n",
    "                    torch.save(self.Q_target.state_dict(), 'model.pth')\n",
    "                    best_reward = episode_reward\n",
    "\n",
    "        return score_values, q_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T16:09:50.422137Z",
     "iopub.status.busy": "2025-03-25T16:09:50.421823Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1, exploration: 0.05, score: 0, Q_value: 2.8661012649536133, Reward : 0.8000000417232513\n",
      "Run: 2, exploration: 0.049930045481805005, score: 0, Q_value: 2.8707621097564697, Reward : 0.8000000417232513\n",
      "Run: 3, exploration: 0.04978047233847824, score: 0, Q_value: 2.8621766567230225, Reward : 0.8000000417232513\n",
      "Run: 4, exploration: 0.049631347264545114, score: 0, Q_value: 2.781841993331909, Reward : 0.8000000417232513\n",
      "Run: 5, exploration: 0.04945298673780488, score: 0, Q_value: 2.9072742462158203, Reward : 1.400000050663948\n",
      "Run: 6, exploration: 0.04921124775983873, score: 0, Q_value: 3.013519048690796, Reward : 2.1000000685453415\n",
      "Run: 7, exploration: 0.048970690464462896, score: 0, Q_value: 2.7857632637023926, Reward : -0.8999999389052391\n",
      "Run: 8, exploration: 0.04873130907530757, score: 0, Q_value: 2.8222570419311523, Reward : -2.6999999433755875\n",
      "Run: 9, exploration: 0.04849309784423923, score: 0, Q_value: 2.6889054775238037, Reward : -1.4999999403953552\n",
      "Run: 10, exploration: 0.048256051051222854, score: 0, Q_value: 2.8932292461395264, Reward : -0.8999999389052391\n",
      "Run: 11, exploration: 0.048020163004184276, score: 0, Q_value: 2.8442726135253906, Reward : -0.8999999389052391\n",
      "Run: 12, exploration: 0.047785428038873756, score: 0, Q_value: 2.827259063720703, Reward : -0.8999999389052391\n",
      "Run: 13, exploration: 0.04755184051872986, score: 0, Q_value: 2.8602144718170166, Reward : -5.699999950826168\n",
      "Run: 14, exploration: 0.04731939483474412, score: 0, Q_value: 2.896831750869751, Reward : -0.8999999389052391\n",
      "Run: 15, exploration: 0.0470880854053263, score: 0, Q_value: 2.721069574356079, Reward : -0.8999999389052391\n",
      "Run: 16, exploration: 0.0468579066761705, score: 0, Q_value: 2.7847278118133545, Reward : -0.8999999389052391\n",
      "Run: 17, exploration: 0.04662885312012165, score: 0, Q_value: 2.7702295780181885, Reward : -1.4999999403953552\n",
      "Run: 18, exploration: 0.04640091923704283, score: 0, Q_value: 2.755225896835327, Reward : -1.4999999403953552\n",
      "Run: 19, exploration: 0.046174099553683276, score: 0, Q_value: 2.7628016471862793, Reward : -0.8999999389052391\n",
      "Run: 20, exploration: 0.04594838862354683, score: 0, Q_value: 2.775651454925537, Reward : -1.4999999403953552\n",
      "Run: 21, exploration: 0.045723781026761244, score: 0, Q_value: 2.9040558338165283, Reward : -0.8999999389052391\n",
      "Run: 22, exploration: 0.045500271369947956, score: 0, Q_value: 2.885265588760376, Reward : -0.8999999389052391\n",
      "Run: 23, exploration: 0.04527785428609273, score: 0, Q_value: 2.7747879028320312, Reward : -3.8999999463558197\n",
      "Run: 24, exploration: 0.045056524434416594, score: 0, Q_value: 2.745866060256958, Reward : -6.8999999538064\n",
      "Run: 25, exploration: 0.04483627650024768, score: 0, Q_value: 2.825112819671631, Reward : -2.6999999433755875\n",
      "Run: 26, exploration: 0.04461710519489368, score: 0, Q_value: 2.870354413986206, Reward : -7.499999955296516\n",
      "Run: 27, exploration: 0.04439900525551476, score: 0, Q_value: 2.7811005115509033, Reward : -6.299999952316284\n",
      "Run: 28, exploration: 0.044181971444997144, score: 0, Q_value: 2.7757132053375244, Reward : -5.699999950826168\n",
      "Run: 29, exploration: 0.043965998551827486, score: 0, Q_value: 2.762022018432617, Reward : -4.499999947845936\n",
      "Run: 30, exploration: 0.04375108138996769, score: 0, Q_value: 2.666665554046631, Reward : -0.8999999389052391\n",
      "Run: 31, exploration: 0.04353721479873023, score: 0, Q_value: 2.8511910438537598, Reward : -6.299999952316284\n",
      "Run: 32, exploration: 0.043324393642654474, score: 0, Q_value: 2.6825716495513916, Reward : -3.8999999463558197\n",
      "Run: 33, exploration: 0.043112612811383226, score: 0, Q_value: 2.787672758102417, Reward : -0.8999999389052391\n",
      "Run: 34, exploration: 0.042901867219540014, score: 0, Q_value: 2.770266056060791, Reward : -1.4999999403953552\n",
      "Run: 35, exploration: 0.04269215180660696, score: 0, Q_value: 2.7623684406280518, Reward : -0.8999999389052391\n",
      "Run: 36, exploration: 0.042483461536803366, score: 0, Q_value: 2.8178188800811768, Reward : -2.6999999433755875\n",
      "Run: 37, exploration: 0.04227579139896474, score: 0, Q_value: 2.64821195602417, Reward : -0.8999999389052391\n",
      "Run: 38, exploration: 0.04206492949278177, score: 0, Q_value: 2.821657419204712, Reward : 2.2000000700354576\n",
      "Run: 39, exploration: 0.04185930524772418, score: 0, Q_value: 2.7193729877471924, Reward : -7.499999955296516\n",
      "Run: 40, exploration: 0.04165468614711033, score: 0, Q_value: 2.840913772583008, Reward : -4.499999947845936\n",
      "Run: 41, exploration: 0.04145106727753444, score: 0, Q_value: 2.8272926807403564, Reward : -0.8999999389052391\n",
      "Run: 42, exploration: 0.04124844374960872, score: 0, Q_value: 2.743276357650757, Reward : -4.499999947845936\n",
      "Run: 43, exploration: 0.04104681069784598, score: 0, Q_value: 2.740117073059082, Reward : -3.8999999463558197\n",
      "Run: 44, exploration: 0.04084616328054283, score: 0, Q_value: 2.8746774196624756, Reward : -8.099999956786633\n",
      "Run: 45, exploration: 0.040646496679663316, score: 0, Q_value: 2.787069320678711, Reward : -2.0999999418854713\n",
      "Run: 46, exploration: 0.04044780610072331, score: 0, Q_value: 2.719431161880493, Reward : -6.299999952316284\n",
      "Run: 47, exploration: 0.04025008677267538, score: 0, Q_value: 2.706742763519287, Reward : -2.0999999418854713\n",
      "Run: 48, exploration: 0.040053333947794166, score: 0, Q_value: 2.6811087131500244, Reward : -3.8999999463558197\n",
      "Run: 49, exploration: 0.03985754290156247, score: 0, Q_value: 2.787367343902588, Reward : -2.0999999418854713\n",
      "Run: 50, exploration: 0.03966270893255773, score: 0, Q_value: 2.7478830814361572, Reward : -3.2999999448657036\n",
      "Run: 51, exploration: 0.03946882736233911, score: 0, Q_value: 2.7650749683380127, Reward : -1.4999999403953552\n",
      "Run: 52, exploration: 0.03927589353533527, score: 0, Q_value: 2.6374728679656982, Reward : -8.099999956786633\n",
      "Run: 53, exploration: 0.03908390281873248, score: 0, Q_value: 2.6599221229553223, Reward : -0.8999999389052391\n",
      "Run: 54, exploration: 0.038892850602363374, score: 0, Q_value: 2.7698099613189697, Reward : -2.6999999433755875\n",
      "Run: 55, exploration: 0.038702732298596325, score: 0, Q_value: 2.8773841857910156, Reward : -0.8999999389052391\n",
      "Run: 56, exploration: 0.0385135433422252, score: 0, Q_value: 2.623087167739868, Reward : -0.8999999389052391\n",
      "Run: 57, exploration: 0.038325279190359746, score: 0, Q_value: 2.767169713973999, Reward : -4.499999947845936\n",
      "Run: 58, exploration: 0.03813793532231663, score: 0, Q_value: 2.64206862449646, Reward : 0.30000006407499313\n",
      "Run: 59, exploration: 0.03795150723951072, score: 0, Q_value: 2.764085292816162, Reward : -0.8999999389052391\n",
      "Run: 60, exploration: 0.03776599046534709, score: 0, Q_value: 2.7448413372039795, Reward : -3.8999999463558197\n",
      "Run: 61, exploration: 0.03758138054511362, score: 0, Q_value: 2.7722766399383545, Reward : -0.8999999389052391\n",
      "Run: 62, exploration: 0.03739393327856937, score: 0, Q_value: 2.860305070877075, Reward : 2.8000000715255737\n",
      "Run: 63, exploration: 0.0372111420700055, score: 0, Q_value: 2.838010311126709, Reward : -2.6999999433755875\n",
      "Run: 64, exploration: 0.03702924439210285, score: 0, Q_value: 2.7773098945617676, Reward : -0.8999999389052391\n",
      "Run: 65, exploration: 0.03684823587705268, score: 0, Q_value: 2.6787219047546387, Reward : -5.699999950826168\n",
      "Run: 66, exploration: 0.03666811217839718, score: 0, Q_value: 2.7220585346221924, Reward : -0.8999999389052391\n",
      "Run: 67, exploration: 0.03648886897092519, score: 0, Q_value: 2.620194673538208, Reward : -3.8999999463558197\n",
      "Run: 68, exploration: 0.03631050195056825, score: 0, Q_value: 2.8560664653778076, Reward : -0.8999999389052391\n",
      "Run: 69, exploration: 0.03613300683429739, score: 0, Q_value: 2.8745946884155273, Reward : -0.8999999389052391\n",
      "Run: 70, exploration: 0.0359563793600201, score: 0, Q_value: 2.776533365249634, Reward : -0.8999999389052391\n",
      "Run: 71, exploration: 0.03578061528647811, score: 0, Q_value: 2.694589376449585, Reward : -0.8999999389052391\n",
      "Run: 72, exploration: 0.035605710393145494, score: 0, Q_value: 2.8238022327423096, Reward : 1.5000000670552254\n",
      "Run: 73, exploration: 0.03543166048012744, score: 0, Q_value: 2.6573872566223145, Reward : -0.8999999389052391\n",
      "Run: 74, exploration: 0.03525846136805922, score: 0, Q_value: 2.7380642890930176, Reward : -0.8999999389052391\n",
      "Run: 75, exploration: 0.03508610889800592, score: 0, Q_value: 2.8379175662994385, Reward : -0.8999999389052391\n",
      "Run: 76, exploration: 0.03491459893136258, score: 0, Q_value: 2.8200039863586426, Reward : -0.8999999389052391\n",
      "Run: 77, exploration: 0.034743927349754865, score: 0, Q_value: 2.7024567127227783, Reward : -4.499999947845936\n",
      "Run: 78, exploration: 0.03457409005494009, score: 0, Q_value: 2.7564375400543213, Reward : -5.099999949336052\n",
      "Run: 79, exploration: 0.03440508296870881, score: 0, Q_value: 2.7491726875305176, Reward : -5.099999949336052\n",
      "Run: 80, exploration: 0.03423690203278694, score: 0, Q_value: 2.8491249084472656, Reward : -5.099999949336052\n",
      "Run: 81, exploration: 0.03406954320873828, score: 0, Q_value: 2.8336341381073, Reward : -0.8999999389052391\n",
      "Run: 82, exploration: 0.03390300247786754, score: 0, Q_value: 2.7860348224639893, Reward : -0.8999999389052391\n",
      "Run: 83, exploration: 0.03373727584112391, score: 0, Q_value: 2.8037211894989014, Reward : -0.8999999389052391\n",
      "Run: 84, exploration: 0.03357235931900491, score: 0, Q_value: 2.8216423988342285, Reward : -0.8999999389052391\n",
      "Run: 85, exploration: 0.03340824895146092, score: 0, Q_value: 2.6965982913970947, Reward : -0.8999999389052391\n",
      "Run: 86, exploration: 0.0332449407978001, score: 0, Q_value: 2.7956395149230957, Reward : -0.8999999389052391\n",
      "Run: 87, exploration: 0.03308243093659362, score: 0, Q_value: 2.731232166290283, Reward : -8.099999956786633\n",
      "Run: 88, exploration: 0.03292071546558174, score: 0, Q_value: 2.779001235961914, Reward : -0.8999999389052391\n",
      "Run: 89, exploration: 0.03275979050157988, score: 0, Q_value: 2.7178614139556885, Reward : -5.099999949336052\n",
      "Run: 90, exploration: 0.03258661427536216, score: 0, Q_value: 2.8242266178131104, Reward : -0.4999999329447746\n",
      "Run: 91, exploration: 0.032427322484310815, score: 0, Q_value: 2.834920883178711, Reward : -3.2999999448657036\n",
      "Run: 92, exploration: 0.032268809352695604, score: 0, Q_value: 2.6109139919281006, Reward : -3.2999999448657036\n",
      "Run: 93, exploration: 0.03211107107422793, score: 0, Q_value: 2.795048952102661, Reward : -0.8999999389052391\n",
      "Run: 94, exploration: 0.031954103861225436, score: 0, Q_value: 2.729954242706299, Reward : -1.4999999403953552\n",
      "Run: 95, exploration: 0.03179790394452086, score: 0, Q_value: 2.7488608360290527, Reward : -7.499999955296516\n",
      "Run: 96, exploration: 0.03164246757337165, score: 0, Q_value: 2.7153284549713135, Reward : -4.499999947845936\n",
      "Run: 97, exploration: 0.031487791015369825, score: 0, Q_value: 2.738636016845703, Reward : -5.099999949336052\n",
      "Run: 98, exploration: 0.03139346448646046, score: 0, Q_value: 2.642658233642578, Reward : 0.8000000417232513\n",
      "Run: 99, exploration: 0.03124000511989056, score: 0, Q_value: 2.8150248527526855, Reward : -5.099999949336052\n",
      "Run: 100, exploration: 0.031087295902358772, score: 0, Q_value: 2.7367265224456787, Reward : -6.8999999538064\n",
      "Run: 101, exploration: 0.03093533316694277, score: 0, Q_value: 2.731555223464966, Reward : -5.699999950826168\n",
      "Run: 102, exploration: 0.03078411326464509, score: 0, Q_value: 2.7035975456237793, Reward : -0.8999999389052391\n",
      "Run: 103, exploration: 0.030633632564305496, score: 0, Q_value: 2.5369162559509277, Reward : -0.8999999389052391\n",
      "Run: 104, exploration: 0.03048388745251381, score: 0, Q_value: 2.704624891281128, Reward : -0.8999999389052391\n",
      "Run: 105, exploration: 0.03033487433352311, score: 0, Q_value: 2.752898693084717, Reward : -5.099999949336052\n",
      "Run: 106, exploration: 0.030186589629163443, score: 0, Q_value: 2.7946419715881348, Reward : -5.099999949336052\n",
      "Run: 107, exploration: 0.030039029778755888, score: 0, Q_value: 2.7268998622894287, Reward : -3.2999999448657036\n",
      "Run: 108, exploration: 0.029892191239026995, score: 0, Q_value: 2.8067665100097656, Reward : -6.299999952316284\n",
      "Run: 109, exploration: 0.029746070484023796, score: 0, Q_value: 2.72753643989563, Reward : -0.8999999389052391\n",
      "Run: 110, exploration: 0.029600664005029066, score: 0, Q_value: 2.696499824523926, Reward : -3.2999999448657036\n",
      "Run: 111, exploration: 0.029455968310477105, score: 0, Q_value: 2.715520143508911, Reward : -3.2999999448657036\n",
      "Run: 112, exploration: 0.029311979925869903, score: 0, Q_value: 2.851895809173584, Reward : -0.8999999389052391\n",
      "Run: 113, exploration: 0.029168695393693673, score: 0, Q_value: 2.7015058994293213, Reward : -0.8999999389052391\n",
      "Run: 114, exploration: 0.029026111273335833, score: 0, Q_value: 2.7501907348632812, Reward : -0.8999999389052391\n",
      "Run: 115, exploration: 0.02886112484765509, score: 0, Q_value: 2.621033191680908, Reward : -1.8999999314546585\n",
      "Run: 116, exploration: 0.028720044211603388, score: 0, Q_value: 2.6165833473205566, Reward : -0.8999999389052391\n",
      "Run: 117, exploration: 0.02857965321415634, score: 0, Q_value: 2.573566436767578, Reward : -0.8999999389052391\n",
      "Run: 118, exploration: 0.02843994848418225, score: 0, Q_value: 2.697436809539795, Reward : -2.0999999418854713\n",
      "Run: 119, exploration: 0.028300926667028367, score: 0, Q_value: 2.7374703884124756, Reward : -4.499999947845936\n",
      "Run: 120, exploration: 0.028162584424440373, score: 0, Q_value: 2.5806310176849365, Reward : -0.8999999389052391\n",
      "Run: 121, exploration: 0.02802491843448217, score: 0, Q_value: 2.6125855445861816, Reward : -0.8999999389052391\n",
      "Run: 122, exploration: 0.02788792539145616, score: 0, Q_value: 2.6827709674835205, Reward : -6.299999952316284\n",
      "Run: 123, exploration: 0.027751602005823838, score: 0, Q_value: 2.613124132156372, Reward : -0.8999999389052391\n",
      "Run: 124, exploration: 0.02761594500412686, score: 0, Q_value: 2.5410404205322266, Reward : -7.499999955296516\n",
      "Run: 125, exploration: 0.027480951128908325, score: 0, Q_value: 2.6618847846984863, Reward : -5.099999949336052\n",
      "Run: 126, exploration: 0.027346617138634666, score: 0, Q_value: 2.650740385055542, Reward : -0.8999999389052391\n",
      "Run: 127, exploration: 0.027212939807617745, score: 0, Q_value: 2.6158535480499268, Reward : -3.2999999448657036\n",
      "Run: 128, exploration: 0.027079915925937427, score: 0, Q_value: 2.6537365913391113, Reward : -0.299999937415123\n",
      "Run: 129, exploration: 0.02694754229936451, score: 0, Q_value: 2.571714401245117, Reward : -0.8999999389052391\n",
      "Run: 130, exploration: 0.026815815749284003, score: 0, Q_value: 2.532738208770752, Reward : -6.299999952316284\n",
      "Run: 131, exploration: 0.026684733112618795, score: 0, Q_value: 2.605802536010742, Reward : -5.699999950826168\n",
      "Run: 132, exploration: 0.02655429124175374, score: 0, Q_value: 2.528635025024414, Reward : -3.2999999448657036\n",
      "Run: 133, exploration: 0.026424487004460012, score: 0, Q_value: 2.547370672225952, Reward : -0.8999999389052391\n",
      "Run: 134, exploration: 0.02629531728381996, score: 0, Q_value: 2.5127079486846924, Reward : -3.8999999463558197\n",
      "Run: 135, exploration: 0.02616677897815223, score: 0, Q_value: 2.661663293838501, Reward : -0.8999999389052391\n",
      "Run: 136, exploration: 0.02601804519516182, score: 0, Q_value: 2.5403759479522705, Reward : -2.4999999329447746\n",
      "Run: 137, exploration: 0.025890862267111348, score: 0, Q_value: 2.557037591934204, Reward : -6.299999952316284\n",
      "Run: 138, exploration: 0.025764301042077605, score: 0, Q_value: 2.6409261226654053, Reward : -2.0999999418854713\n",
      "Run: 139, exploration: 0.025638358481015602, score: 0, Q_value: 2.641148567199707, Reward : -1.4999999403953552\n",
      "Run: 140, exploration: 0.02551303155973599, score: 0, Q_value: 2.662658929824829, Reward : -0.8999999389052391\n",
      "Run: 141, exploration: 0.02538831726883242, score: 0, Q_value: 2.6633262634277344, Reward : -0.8999999389052391\n",
      "Run: 142, exploration: 0.02526421261360931, score: 0, Q_value: 2.568777561187744, Reward : -5.099999949336052\n",
      "Run: 143, exploration: 0.025140714614009928, score: 0, Q_value: 2.6854705810546875, Reward : -0.8999999389052391\n",
      "Run: 144, exploration: 0.025017820304544816, score: 0, Q_value: 2.5248043537139893, Reward : 0.30000006407499313\n",
      "Run: 145, exploration: 0.02489552673422061, score: 0, Q_value: 2.6336467266082764, Reward : -5.099999949336052\n",
      "Run: 146, exploration: 0.02477383096646916, score: 0, Q_value: 2.6595118045806885, Reward : -0.8999999389052391\n",
      "Run: 147, exploration: 0.024652730079077, score: 0, Q_value: 2.6435861587524414, Reward : -5.099999949336052\n",
      "Run: 148, exploration: 0.024532221164115228, score: 0, Q_value: 2.6723875999450684, Reward : -0.8999999389052391\n",
      "Run: 149, exploration: 0.024412301327869642, score: 0, Q_value: 2.5894181728363037, Reward : -0.8999999389052391\n",
      "Run: 150, exploration: 0.024292967690771248, score: 0, Q_value: 2.6084420680999756, Reward : -6.299999952316284\n",
      "Run: 151, exploration: 0.024174217387327144, score: 0, Q_value: 2.441946029663086, Reward : -0.8999999389052391\n",
      "Run: 152, exploration: 0.024056047566051685, score: 0, Q_value: 2.643416404724121, Reward : -0.8999999389052391\n",
      "Run: 153, exploration: 0.02393845538939803, score: 0, Q_value: 2.5732522010803223, Reward : -3.2999999448657036\n",
      "Run: 154, exploration: 0.023821438033690003, score: 0, Q_value: 2.4476375579833984, Reward : -4.499999947845936\n",
      "Run: 155, exploration: 0.023690773248715713, score: 0, Q_value: 2.4976468086242676, Reward : -1.4999999329447746\n",
      "Run: 156, exploration: 0.02357496662731313, score: 0, Q_value: 2.5299947261810303, Reward : -0.8999999389052391\n",
      "Run: 157, exploration: 0.02345972609860071, score: 0, Q_value: 2.4329311847686768, Reward : -0.8999999389052391\n",
      "Run: 158, exploration: 0.023345048895371104, score: 0, Q_value: 2.500725030899048, Reward : -0.8999999389052391\n",
      "Run: 159, exploration: 0.023230932263943807, score: 0, Q_value: 2.41328763961792, Reward : -0.8999999389052391\n",
      "Run: 160, exploration: 0.023117373464098985, score: 0, Q_value: 2.4792938232421875, Reward : 0.30000006407499313\n",
      "Run: 161, exploration: 0.023004369769011716, score: 0, Q_value: 2.348233699798584, Reward : -0.8999999389052391\n",
      "Run: 162, exploration: 0.022891918465186515, score: 0, Q_value: 2.4716737270355225, Reward : -0.8999999389052391\n",
      "Run: 163, exploration: 0.022780016852392154, score: 0, Q_value: 2.4343693256378174, Reward : -0.8999999389052391\n",
      "Run: 164, exploration: 0.022668662243596815, score: 0, Q_value: 2.483487367630005, Reward : -0.8999999389052391\n",
      "Run: 165, exploration: 0.022557851964903626, score: 0, Q_value: 2.5293822288513184, Reward : -5.699999950826168\n",
      "Run: 166, exploration: 0.02244758335548637, score: 0, Q_value: 2.43615984916687, Reward : -5.099999949336052\n",
      "Run: 167, exploration: 0.02233785376752567, score: 0, Q_value: 2.47837495803833, Reward : -5.099999949336052\n",
      "Run: 168, exploration: 0.02222866056614534, score: 0, Q_value: 2.4321625232696533, Reward : -5.099999949336052\n",
      "Run: 169, exploration: 0.0221200011293492, score: 0, Q_value: 2.5016865730285645, Reward : -0.8999999389052391\n",
      "Run: 170, exploration: 0.021998669025589966, score: 0, Q_value: 2.407773971557617, Reward : -0.2999999299645424\n",
      "Run: 171, exploration: 0.021891133846874525, score: 0, Q_value: 2.3862061500549316, Reward : -2.0999999418854713\n",
      "Run: 172, exploration: 0.02178412432790004, score: 0, Q_value: 2.394620180130005, Reward : -0.8999999389052391\n",
      "Run: 173, exploration: 0.02167763789910587, score: 0, Q_value: 2.4700262546539307, Reward : -0.8999999389052391\n",
      "Run: 174, exploration: 0.021571672003492044, score: 0, Q_value: 2.305535078048706, Reward : -4.499999947845936\n",
      "Run: 175, exploration: 0.021466224096557858, score: 0, Q_value: 2.3933920860290527, Reward : -0.8999999389052391\n",
      "Run: 176, exploration: 0.021361291646240815, score: 0, Q_value: 2.391400098800659, Reward : -0.8999999389052391\n",
      "Run: 177, exploration: 0.02125687213285576, score: 0, Q_value: 2.4511542320251465, Reward : -0.8999999389052391\n",
      "Run: 178, exploration: 0.02115296304903442, score: 0, Q_value: 2.4108235836029053, Reward : -5.099999949336052\n",
      "Run: 179, exploration: 0.021049561899665194, score: 0, Q_value: 2.490567922592163, Reward : -0.8999999389052391\n",
      "Run: 180, exploration: 0.02093410134369317, score: 0, Q_value: 2.1749913692474365, Reward : 1.500000074505806\n",
      "Run: 181, exploration: 0.020831770046894165, score: 0, Q_value: 2.195836305618286, Reward : -2.0999999418854713\n",
      "Run: 182, exploration: 0.020729938971916603, score: 0, Q_value: 2.2883944511413574, Reward : -6.299999952316284\n",
      "Run: 183, exploration: 0.02062860567354696, score: 0, Q_value: 2.2814719676971436, Reward : -0.8999999389052391\n",
      "Run: 184, exploration: 0.02052776771852455, score: 0, Q_value: 2.2289228439331055, Reward : -3.2999999448657036\n",
      "Run: 185, exploration: 0.020427422685483115, score: 0, Q_value: 2.2199277877807617, Reward : -1.4999999403953552\n",
      "Run: 186, exploration: 0.02032756816489261, score: 0, Q_value: 2.2552216053009033, Reward : -0.8999999389052391\n",
      "Run: 187, exploration: 0.020266673802845206, score: 0, Q_value: 2.2378363609313965, Reward : 0.8000000417232513\n",
      "Run: 188, exploration: 0.02016760506433101, score: 0, Q_value: 2.2761080265045166, Reward : -5.699999950826168\n",
      "Run: 189, exploration: 0.020069020599410327, score: 0, Q_value: 2.221067190170288, Reward : 0.9000000655651093\n",
      "Run: 190, exploration: 0.019970918040828668, score: 0, Q_value: 2.2228779792785645, Reward : -0.8999999389052391\n",
      "Run: 191, exploration: 0.01987329503290335, score: 0, Q_value: 2.308182716369629, Reward : -0.8999999389052391\n",
      "Run: 192, exploration: 0.01977614923146682, score: 0, Q_value: 2.2464284896850586, Reward : -2.6999999433755875\n",
      "Run: 193, exploration: 0.01967947830381047, score: 0, Q_value: 2.303490161895752, Reward : -1.4999999403953552\n",
      "Run: 194, exploration: 0.019583279928628544, score: 0, Q_value: 2.2521841526031494, Reward : -5.099999949336052\n",
      "Run: 195, exploration: 0.019487551795962434, score: 0, Q_value: 2.24074387550354, Reward : -0.8999999389052391\n",
      "Run: 196, exploration: 0.01942917383235878, score: 0, Q_value: 2.25990629196167, Reward : 0.8000000417232513\n",
      "Run: 197, exploration: 0.019322601390449817, score: 0, Q_value: 2.2312870025634766, Reward : -0.8999999314546585\n",
      "Run: 198, exploration: 0.019228147521838396, score: 0, Q_value: 2.0956408977508545, Reward : -2.6999999433755875\n",
      "Run: 199, exploration: 0.019134155368143897, score: 0, Q_value: 2.121049642562866, Reward : -0.8999999389052391\n",
      "Run: 200, exploration: 0.01901778648780061, score: 1, Q_value: 2.0227861404418945, Reward : -2.9999999329447746\n",
      "Run: 201, exploration: 0.018924822633198366, score: 0, Q_value: 2.053713083267212, Reward : -5.699999950826168\n",
      "Run: 202, exploration: 0.018832313209939562, score: 0, Q_value: 2.0026133060455322, Reward : -2.6999999433755875\n",
      "Run: 203, exploration: 0.018740255996646332, score: 0, Q_value: 2.132965564727783, Reward : -2.0999999418854713\n",
      "Run: 204, exploration: 0.018648648782799527, score: 0, Q_value: 2.076529026031494, Reward : -3.8999999463558197\n",
      "Run: 205, exploration: 0.018557489368685575, score: 0, Q_value: 2.040663242340088, Reward : -4.499999947845936\n",
      "Run: 206, exploration: 0.01846677556534365, score: 0, Q_value: 2.1334002017974854, Reward : -4.499999947845936\n",
      "Run: 207, exploration: 0.018376505194513167, score: 0, Q_value: 2.0554494857788086, Reward : 0.9000000655651093\n",
      "Run: 208, exploration: 0.018286676088581415, score: 0, Q_value: 2.0308279991149902, Reward : -7.499999955296516\n",
      "Run: 209, exploration: 0.018197286090531554, score: 0, Q_value: 2.0550804138183594, Reward : -0.8999999389052391\n",
      "Run: 210, exploration: 0.01810833305389081, score: 0, Q_value: 2.122279405593872, Reward : -2.6999999433755875\n",
      "Run: 211, exploration: 0.018019814842678873, score: 0, Q_value: 2.031782388687134, Reward : -4.499999947845936\n",
      "Run: 212, exploration: 0.01793172933135669, score: 0, Q_value: 2.1453170776367188, Reward : 0.30000006407499313\n",
      "Run: 213, exploration: 0.017844074404775385, score: 0, Q_value: 2.143171548843384, Reward : -0.8999999389052391\n",
      "Run: 214, exploration: 0.017756847958125505, score: 0, Q_value: 2.089649200439453, Reward : -0.8999999389052391\n",
      "Run: 215, exploration: 0.017657682573450247, score: 0, Q_value: 2.0112078189849854, Reward : -1.9999999329447746\n",
      "Run: 216, exploration: 0.017571367258236062, score: 0, Q_value: 2.0508134365081787, Reward : -0.8999999389052391\n",
      "Run: 217, exploration: 0.01748547387458676, score: 0, Q_value: 2.0701560974121094, Reward : -5.699999950826168\n",
      "Run: 218, exploration: 0.017400000359991827, score: 0, Q_value: 2.054755210876465, Reward : -0.8999999389052391\n",
      "Run: 219, exploration: 0.017314944662022845, score: 0, Q_value: 2.0932281017303467, Reward : -0.8999999389052391\n",
      "Run: 220, exploration: 0.017230304738284158, score: 0, Q_value: 2.007716655731201, Reward : -2.0999999418854713\n",
      "Run: 221, exploration: 0.017146078556363905, score: 0, Q_value: 2.1420838832855225, Reward : -2.0999999418854713\n",
      "Run: 222, exploration: 0.01706226409378516, score: 0, Q_value: 2.0567948818206787, Reward : -0.8999999389052391\n",
      "Run: 223, exploration: 0.0169788593379574, score: 0, Q_value: 2.0580079555511475, Reward : -0.8999999389052391\n",
      "Run: 224, exploration: 0.016895862286128153, score: 0, Q_value: 2.0344860553741455, Reward : -4.499999947845936\n",
      "Run: 225, exploration: 0.016813270945334916, score: 0, Q_value: 2.0364861488342285, Reward : 0.30000006407499313\n",
      "Run: 226, exploration: 0.016731083332357313, score: 0, Q_value: 2.0509705543518066, Reward : -3.2999999448657036\n",
      "Run: 227, exploration: 0.016649297473669448, score: 0, Q_value: 2.0361669063568115, Reward : -3.8999999463558197\n",
      "Run: 228, exploration: 0.016557973143404698, score: 0, Q_value: 2.032288074493408, Reward : 0.9000000730156898\n",
      "Run: 229, exploration: 0.016477033492052613, score: 0, Q_value: 1.8973004817962646, Reward : -0.8999999389052391\n",
      "Run: 230, exploration: 0.016383376893134627, score: 0, Q_value: 1.9595146179199219, Reward : 2.9000000804662704\n",
      "Run: 231, exploration: 0.016303290713370017, score: 0, Q_value: 1.8898838758468628, Reward : -0.8999999389052391\n",
      "Run: 232, exploration: 0.016223596015546606, score: 0, Q_value: 1.9019547700881958, Reward : -0.8999999389052391\n",
      "Run: 233, exploration: 0.016144290885999488, score: 0, Q_value: 1.8745359182357788, Reward : -0.8999999389052391\n",
      "Run: 234, exploration: 0.016062160506387913, score: 0, Q_value: 1.8273341655731201, Reward : 2.90000007301569\n",
      "Run: 235, exploration: 0.01598364451532494, score: 0, Q_value: 1.7864927053451538, Reward : -0.8999999389052391\n",
      "Run: 236, exploration: 0.01590551233071504, score: 0, Q_value: 1.7661782503128052, Reward : -3.8999999463558197\n",
      "Run: 237, exploration: 0.0158166859662357, score: 0, Q_value: 1.6708619594573975, Reward : -1.3999999314546585\n",
      "Run: 238, exploration: 0.015725210150081232, score: 0, Q_value: 1.5773459672927856, Reward : 3.6000000834465027\n",
      "Run: 239, exploration: 0.015648341259428808, score: 0, Q_value: 1.6058552265167236, Reward : -0.8999999389052391\n",
      "Run: 240, exploration: 0.015551616862805233, score: 1, Q_value: 1.4863009452819824, Reward : 0.10000007599592209\n",
      "Run: 241, exploration: 0.015475596540998017, score: 0, Q_value: 1.5377670526504517, Reward : -4.499999947845936\n",
      "Run: 242, exploration: 0.015399947826167666, score: 0, Q_value: 1.6040828227996826, Reward : -5.099999949336052\n",
      "Run: 243, exploration: 0.015324668901803245, score: 0, Q_value: 1.5497674942016602, Reward : -0.8999999389052391\n",
      "Run: 244, exploration: 0.015249757960273405, score: 0, Q_value: 1.5850974321365356, Reward : -0.8999999389052391\n",
      "Run: 245, exploration: 0.015175213202782962, score: 0, Q_value: 1.5661896467208862, Reward : -2.0999999418854713\n",
      "Run: 246, exploration: 0.015101032839329705, score: 0, Q_value: 1.5130317211151123, Reward : -0.8999999389052391\n",
      "Run: 247, exploration: 0.015027215088661424, score: 0, Q_value: 1.5063880681991577, Reward : -8.099999956786633\n",
      "Run: 248, exploration: 0.014953758178233124, score: 0, Q_value: 1.5175514221191406, Reward : -0.8999999389052391\n",
      "Run: 249, exploration: 0.014880660344164479, score: 0, Q_value: 1.51958429813385, Reward : -8.699999958276749\n",
      "Run: 250, exploration: 0.014807919831197443, score: 0, Q_value: 1.556384563446045, Reward : -0.8999999389052391\n",
      "Run: 251, exploration: 0.014735534892654147, score: 0, Q_value: 1.5064760446548462, Reward : -1.4999999403953552\n",
      "Run: 252, exploration: 0.014663503790394923, score: 0, Q_value: 1.5008881092071533, Reward : -0.8999999389052391\n",
      "Run: 253, exploration: 0.014591824794776586, score: 0, Q_value: 1.4967148303985596, Reward : -0.8999999389052391\n",
      "Run: 254, exploration: 0.014520496184610878, score: 0, Q_value: 1.5519440174102783, Reward : -0.8999999389052391\n",
      "Run: 255, exploration: 0.014449516247123182, score: 0, Q_value: 1.5267459154129028, Reward : -7.499999955296516\n",
      "Run: 256, exploration: 0.014378883277911337, score: 0, Q_value: 1.5040556192398071, Reward : -0.8999999389052391\n",
      "Run: 257, exploration: 0.014308595580904757, score: 0, Q_value: 1.5517480373382568, Reward : -0.8999999389052391\n",
      "Run: 258, exploration: 0.014238651468323692, score: 0, Q_value: 1.502497673034668, Reward : -0.8999999389052391\n",
      "Run: 259, exploration: 0.014169049260638679, score: 0, Q_value: 1.583568811416626, Reward : -0.8999999389052391\n",
      "Run: 260, exploration: 0.014099787286530238, score: 0, Q_value: 1.538632869720459, Reward : -1.4999999403953552\n",
      "Run: 261, exploration: 0.014030863882848726, score: 0, Q_value: 1.4844601154327393, Reward : -2.6999999433755875\n",
      "Run: 262, exploration: 0.01396227739457441, score: 0, Q_value: 1.5471217632293701, Reward : -5.099999949336052\n",
      "Run: 263, exploration: 0.01389402617477773, score: 0, Q_value: 1.5414650440216064, Reward : -0.299999937415123\n",
      "Run: 264, exploration: 0.01382610858457973, score: 0, Q_value: 1.5325884819030762, Reward : -6.299999952316284\n",
      "Run: 265, exploration: 0.013784690346302206, score: 0, Q_value: 1.5528199672698975, Reward : 0.8000000417232513\n",
      "Run: 266, exploration: 0.013717307217886469, score: 0, Q_value: 1.5214394330978394, Reward : -2.0999999418854713\n",
      "Run: 267, exploration: 0.013650253475614426, score: 0, Q_value: 1.500162124633789, Reward : -3.8999999463558197\n",
      "Run: 268, exploration: 0.013609362038407563, score: 0, Q_value: 1.555804967880249, Reward : 0.8000000417232513\n",
      "Run: 269, exploration: 0.013542835960066144, score: 0, Q_value: 1.5191714763641357, Reward : -8.699999958276749\n",
      "Run: 270, exploration: 0.013476635078386192, score: 0, Q_value: 1.5951262712478638, Reward : 0.30000006407499313\n",
      "Run: 271, exploration: 0.013410757803722391, score: 0, Q_value: 1.533123254776001, Reward : -0.8999999389052391\n",
      "Run: 272, exploration: 0.01334119939377649, score: 0, Q_value: 1.488468885421753, Reward : -0.5999999344348907\n",
      "Run: 273, exploration: 0.013275984163736024, score: 0, Q_value: 1.442199945449829, Reward : -0.8999999389052391\n",
      "Run: 274, exploration: 0.013211087722591794, score: 0, Q_value: 1.3994227647781372, Reward : 0.30000006407499313\n",
      "Run: 275, exploration: 0.013146508512021302, score: 0, Q_value: 1.4358866214752197, Reward : -5.699999950826168\n",
      "Run: 276, exploration: 0.013082244981319527, score: 0, Q_value: 1.505162239074707, Reward : -5.699999950826168\n",
      "Run: 277, exploration: 0.013002682221868574, score: 1, Q_value: 1.4465670585632324, Reward : 0.6000000759959221\n",
      "Run: 278, exploration: 0.012930067082775058, score: 0, Q_value: 1.3715940713882446, Reward : -0.19999992847442627\n",
      "Run: 279, exploration: 0.01286686157370852, score: 0, Q_value: 1.3748029470443726, Reward : -7.499999955296516\n",
      "Run: 280, exploration: 0.012803965029502776, score: 0, Q_value: 1.4053635597229004, Reward : -5.099999949336052\n",
      "Run: 281, exploration: 0.012741375939857767, score: 0, Q_value: 1.4438343048095703, Reward : -7.499999955296516\n",
      "Run: 282, exploration: 0.012695587166244287, score: 0, Q_value: 1.394524097442627, Reward : 1.400000050663948\n",
      "Run: 283, exploration: 0.012633527855600022, score: 0, Q_value: 1.406835675239563, Reward : -5.099999949336052\n",
      "Run: 284, exploration: 0.012571771906902486, score: 0, Q_value: 1.3750511407852173, Reward : -3.8999999463558197\n",
      "Run: 285, exploration: 0.012510317837240093, score: 0, Q_value: 1.3777350187301636, Reward : -3.8999999463558197\n",
      "Run: 286, exploration: 0.012449164170950124, score: 0, Q_value: 1.3787715435028076, Reward : -3.2999999448657036\n",
      "Run: 287, exploration: 0.012388309439583255, score: 0, Q_value: 1.3421354293823242, Reward : -0.8999999389052391\n",
      "Run: 288, exploration: 0.012327752181868344, score: 0, Q_value: 1.3365647792816162, Reward : -0.8999999389052391\n",
      "Run: 289, exploration: 0.012267490943677312, score: 0, Q_value: 1.3658431768417358, Reward : -0.8999999389052391\n",
      "Run: 290, exploration: 0.012207524277990227, score: 0, Q_value: 1.431281328201294, Reward : -3.2999999448657036\n",
      "Run: 291, exploration: 0.01214785074486058, score: 0, Q_value: 1.4086412191390991, Reward : -0.8999999389052391\n",
      "Run: 292, exploration: 0.01208846891138068, score: 0, Q_value: 1.3957730531692505, Reward : -0.8999999389052391\n",
      "Run: 293, exploration: 0.012029377351647268, score: 0, Q_value: 1.3624759912490845, Reward : -3.2999999448657036\n",
      "Run: 294, exploration: 0.011970574646727255, score: 0, Q_value: 1.3902093172073364, Reward : -0.8999999389052391\n",
      "Run: 295, exploration: 0.011912059384623669, score: 0, Q_value: 1.3983640670776367, Reward : -0.8999999389052391\n",
      "Run: 296, exploration: 0.011853830160241765, score: 0, Q_value: 1.4195319414138794, Reward : -0.8999999389052391\n",
      "Run: 297, exploration: 0.011795885575355235, score: 0, Q_value: 1.4634064435958862, Reward : -5.099999949336052\n",
      "Run: 298, exploration: 0.01173822423857267, score: 0, Q_value: 1.4815212488174438, Reward : -0.8999999389052391\n",
      "Run: 299, exploration: 0.011680844765304151, score: 0, Q_value: 1.3695000410079956, Reward : -0.299999937415123\n",
      "Run: 300, exploration: 0.011623745777727993, score: 0, Q_value: 1.3417279720306396, Reward : 1.5000000670552254\n",
      "Run: 301, exploration: 0.011566925904757639, score: 0, Q_value: 1.3670356273651123, Reward : -0.8999999389052391\n",
      "Run: 302, exploration: 0.011510383782008781, score: 0, Q_value: 1.4432414770126343, Reward : -7.499999955296516\n",
      "Run: 303, exploration: 0.011454118051766573, score: 0, Q_value: 1.3751486539840698, Reward : -0.8999999389052391\n",
      "Run: 304, exploration: 0.01139812736295301, score: 0, Q_value: 1.4111144542694092, Reward : -0.8999999389052391\n",
      "Run: 305, exploration: 0.011342410371094513, score: 0, Q_value: 1.4034135341644287, Reward : -0.8999999389052391\n",
      "Run: 306, exploration: 0.011286965738289656, score: 0, Q_value: 1.4286444187164307, Reward : -0.8999999389052391\n",
      "Run: 307, exploration: 0.011231792133176996, score: 0, Q_value: 1.3996199369430542, Reward : -0.8999999389052391\n",
      "Run: 308, exploration: 0.011176888230903145, score: 0, Q_value: 1.380456805229187, Reward : -0.8999999389052391\n",
      "Run: 309, exploration: 0.011122252713090936, score: 0, Q_value: 1.3418200016021729, Reward : -0.8999999389052391\n",
      "Run: 310, exploration: 0.01106788426780776, score: 0, Q_value: 1.3957144021987915, Reward : -0.8999999389052391\n",
      "Run: 311, exploration: 0.011013781589534087, score: 0, Q_value: 1.4293253421783447, Reward : -0.8999999389052391\n",
      "Run: 312, exploration: 0.0109599433791321, score: 0, Q_value: 1.4241074323654175, Reward : -0.8999999389052391\n",
      "Run: 313, exploration: 0.010906368343814506, score: 0, Q_value: 1.4131267070770264, Reward : -5.699999950826168\n",
      "Run: 314, exploration: 0.010853055197113487, score: 0, Q_value: 1.4527426958084106, Reward : -3.8999999463558197\n",
      "Run: 315, exploration: 0.010800002658849811, score: 0, Q_value: 1.391426920890808, Reward : -0.8999999389052391\n",
      "Run: 316, exploration: 0.010747209455102094, score: 0, Q_value: 1.4370534420013428, Reward : -0.8999999389052391\n",
      "Run: 317, exploration: 0.010694674318176204, score: 0, Q_value: 1.3851460218429565, Reward : 0.30000006407499313\n",
      "Run: 318, exploration: 0.010642395986574835, score: 0, Q_value: 1.4438526630401611, Reward : -4.499999947845936\n",
      "Run: 319, exploration: 0.010590373204967205, score: 0, Q_value: 1.3824180364608765, Reward : -0.8999999389052391\n",
      "Run: 320, exploration: 0.010538604724158906, score: 0, Q_value: 1.4205111265182495, Reward : -0.8999999389052391\n",
      "Run: 321, exploration: 0.01048708930106192, score: 0, Q_value: 1.3499984741210938, Reward : -0.8999999389052391\n",
      "Run: 322, exploration: 0.010435825698664766, score: 0, Q_value: 1.4191926717758179, Reward : -1.4999999403953552\n",
      "Run: 323, exploration: 0.01036717262072264, score: 1, Q_value: 1.3535445928573608, Reward : 1.1000000834465027\n",
      "Run: 324, exploration: 0.01031340056296972, score: 0, Q_value: 1.3547321557998657, Reward : 6.705522537231445e-08\n",
      "Run: 325, exploration: 0.010251702354359661, score: 1, Q_value: 1.2512348890304565, Reward : -3.9999999329447746\n",
      "Run: 326, exploration: 0.010201589384182646, score: 0, Q_value: 1.1519548892974854, Reward : -0.8999999389052391\n",
      "Run: 327, exploration: 0.010151721379153189, score: 0, Q_value: 1.2063486576080322, Reward : -3.2999999448657036\n",
      "Run: 328, exploration: 0.010102097141818334, score: 0, Q_value: 1.184166431427002, Reward : -0.8999999389052391\n",
      "Run: 329, exploration: 0.010052715480578624, score: 0, Q_value: 1.2593038082122803, Reward : -0.8999999389052391\n",
      "Run: 330, exploration: 0.010003575209659422, score: 0, Q_value: 1.2284902334213257, Reward : 0.9000000655651093\n",
      "Run: 331, exploration: 0.009954675149082451, score: 0, Q_value: 1.184033751487732, Reward : -0.8999999389052391\n",
      "Run: 332, exploration: 0.009906014124637494, score: 0, Q_value: 1.1977638006210327, Reward : -6.299999952316284\n",
      "Run: 333, exploration: 0.009857590967854168, score: 0, Q_value: 1.181203842163086, Reward : -5.099999949336052\n",
      "Run: 334, exploration: 0.00980057958247126, score: 0, Q_value: 1.2209590673446655, Reward : 0.6000000759959221\n",
      "Run: 335, exploration: 0.009752671816974633, score: 0, Q_value: 1.1679205894470215, Reward : -4.499999947845936\n",
      "Run: 336, exploration: 0.009701116819981525, score: 0, Q_value: 1.1455219984054565, Reward : 3.100000075995922\n",
      "Run: 337, exploration: 0.009653695254169413, score: 0, Q_value: 1.1131601333618164, Reward : 0.9000000655651093\n",
      "Run: 338, exploration: 0.009606505497224851, score: 0, Q_value: 1.0772968530654907, Reward : -0.8999999389052391\n",
      "Run: 339, exploration: 0.0095595464160062, score: 0, Q_value: 1.0871920585632324, Reward : -7.499999955296516\n",
      "Run: 340, exploration: 0.009512816882910904, score: 0, Q_value: 1.0392082929611206, Reward : -4.499999947845936\n",
      "Run: 341, exploration: 0.00946631577584842, score: 0, Q_value: 1.056560754776001, Reward : -0.8999999389052391\n",
      "Run: 342, exploration: 0.009420041978213273, score: 0, Q_value: 1.052200436592102, Reward : -2.6999999433755875\n",
      "Run: 343, exploration: 0.009373994378858254, score: 0, Q_value: 1.081982970237732, Reward : -0.8999999389052391\n",
      "Run: 344, exploration: 0.00932817187206771, score: 0, Q_value: 1.1147717237472534, Reward : -0.8999999389052391\n",
      "Run: 345, exploration: 0.00928257335753102, score: 0, Q_value: 1.0631556510925293, Reward : -0.299999937415123\n",
      "Run: 346, exploration: 0.009237197740316172, score: 0, Q_value: 1.1423530578613281, Reward : -0.8999999389052391\n",
      "Run: 347, exploration: 0.00919204393084346, score: 0, Q_value: 1.10019052028656, Reward : -8.699999958276749\n",
      "Run: 348, exploration: 0.009147110844859323, score: 0, Q_value: 1.0827444791793823, Reward : -0.8999999389052391\n",
      "Run: 349, exploration: 0.009102397403410315, score: 0, Q_value: 1.0873987674713135, Reward : -0.8999999389052391\n",
      "Run: 350, exploration: 0.009057902532817191, score: 0, Q_value: 1.0335652828216553, Reward : -0.8999999389052391\n",
      "Run: 351, exploration: 0.009013625164649118, score: 0, Q_value: 1.069053292274475, Reward : -9.299999959766865\n",
      "Run: 352, exploration: 0.00896956423569805, score: 0, Q_value: 1.044195532798767, Reward : -0.8999999389052391\n",
      "Run: 353, exploration: 0.008925718687953166, score: 0, Q_value: 1.0276530981063843, Reward : -5.699999950826168\n",
      "Run: 354, exploration: 0.008882087468575469, score: 0, Q_value: 1.1113910675048828, Reward : -0.8999999389052391\n",
      "Run: 355, exploration: 0.008838669529872526, score: 0, Q_value: 1.0806094408035278, Reward : -9.299999959766865\n",
      "Run: 356, exploration: 0.00879546382927328, score: 0, Q_value: 1.1016792058944702, Reward : -5.099999949336052\n",
      "Run: 357, exploration: 0.008752469329303039, score: 0, Q_value: 1.107003092765808, Reward : -0.8999999389052391\n",
      "Run: 358, exploration: 0.008709684997558555, score: 0, Q_value: 1.0111548900604248, Reward : 2.1000000685453415\n",
      "Run: 359, exploration: 0.008667109806683228, score: 0, Q_value: 1.0773322582244873, Reward : -0.8999999389052391\n",
      "Run: 360, exploration: 0.008624742734342451, score: 0, Q_value: 1.0465800762176514, Reward : -8.699999958276749\n",
      "Run: 361, exploration: 0.008582582763199042, score: 0, Q_value: 1.1159937381744385, Reward : -0.8999999389052391\n",
      "Run: 362, exploration: 0.008540628880888846, score: 0, Q_value: 1.1441798210144043, Reward : -0.8999999389052391\n",
      "Run: 363, exploration: 0.008498880079996383, score: 0, Q_value: 1.0863940715789795, Reward : -0.8999999389052391\n",
      "Run: 364, exploration: 0.008457335358030687, score: 0, Q_value: 1.0651384592056274, Reward : -0.8999999389052391\n",
      "Run: 365, exploration: 0.008415993717401236, score: 0, Q_value: 1.092158317565918, Reward : -0.8999999389052391\n",
      "Run: 366, exploration: 0.00837485416539397, score: 0, Q_value: 1.0673526525497437, Reward : -0.8999999389052391\n",
      "Run: 367, exploration: 0.008333915714147499, score: 0, Q_value: 1.072286605834961, Reward : -5.099999949336052\n",
      "Run: 368, exploration: 0.008293177380629332, score: 0, Q_value: 1.0582033395767212, Reward : -9.299999959766865\n",
      "Run: 369, exploration: 0.008252638186612303, score: 0, Q_value: 1.0220006704330444, Reward : -6.8999999538064\n",
      "Run: 370, exploration: 0.008212297158651072, score: 0, Q_value: 1.0675214529037476, Reward : -2.6999999433755875\n",
      "Run: 371, exploration: 0.008172153328058753, score: 0, Q_value: 1.0793999433517456, Reward : -0.8999999389052391\n",
      "Run: 372, exploration: 0.00812976631312242, score: 0, Q_value: 1.0798094272613525, Reward : 6.705522537231445e-08\n",
      "Run: 373, exploration: 0.008090025914629253, score: 0, Q_value: 1.0316828489303589, Reward : -0.8999999389052391\n",
      "Run: 374, exploration: 0.008050479777472948, score: 0, Q_value: 1.0544688701629639, Reward : -0.8999999389052391\n",
      "Run: 375, exploration: 0.0080111269520539, score: 0, Q_value: 1.0653343200683594, Reward : -3.2999999448657036\n",
      "Run: 376, exploration: 0.007971966493414376, score: 0, Q_value: 1.0321447849273682, Reward : -3.8999999463558197\n",
      "Run: 377, exploration: 0.007932997461215856, score: 0, Q_value: 1.04725182056427, Reward : -8.099999956786633\n",
      "Run: 378, exploration: 0.00789421891971643, score: 0, Q_value: 1.0319926738739014, Reward : -2.0999999418854713\n",
      "Run: 379, exploration: 0.007855629937748337, score: 0, Q_value: 1.0139039754867554, Reward : -0.8999999389052391\n",
      "Run: 380, exploration: 0.007817229588695608, score: 0, Q_value: 1.0462770462036133, Reward : -0.8999999389052391\n",
      "Run: 381, exploration: 0.007779016950471808, score: 0, Q_value: 1.069878339767456, Reward : -6.8999999538064\n",
      "Run: 382, exploration: 0.0077409911054978995, score: 0, Q_value: 1.0142768621444702, Reward : -0.8999999389052391\n",
      "Run: 383, exploration: 0.007703151140680206, score: 0, Q_value: 1.073049545288086, Reward : -0.8999999389052391\n",
      "Run: 384, exploration: 0.0076654961473885, score: 0, Q_value: 1.0367070436477661, Reward : -7.499999955296516\n",
      "Run: 385, exploration: 0.0076280252214341576, score: 0, Q_value: 1.0419360399246216, Reward : -0.8999999389052391\n",
      "Run: 386, exploration: 0.0075907374630484765, score: 0, Q_value: 1.0375704765319824, Reward : -1.4999999403953552\n",
      "Run: 387, exploration: 0.007553631976861045, score: 0, Q_value: 1.0552022457122803, Reward : -3.2999999448657036\n",
      "Run: 388, exploration: 0.007512198974510991, score: 0, Q_value: 0.975207507610321, Reward : -1.4999999329447746\n",
      "Run: 389, exploration: 0.0074754774047501036, score: 0, Q_value: 0.977979302406311, Reward : -0.8999999389052391\n",
      "Run: 390, exploration: 0.007438935339511162, score: 0, Q_value: 0.977074146270752, Reward : -1.4999999403953552\n",
      "Run: 391, exploration: 0.007402571901329681, score: 0, Q_value: 0.9833834171295166, Reward : -2.0999999418854713\n",
      "Run: 392, exploration: 0.007366386217030444, score: 0, Q_value: 0.9329511523246765, Reward : -5.699999950826168\n",
      "Run: 393, exploration: 0.007330377417706546, score: 0, Q_value: 0.9167116284370422, Reward : -7.499999955296516\n",
      "Run: 394, exploration: 0.007294544638698519, score: 0, Q_value: 0.9929366707801819, Reward : -0.8999999389052391\n",
      "Run: 395, exploration: 0.007258887019573575, score: 0, Q_value: 0.9335305690765381, Reward : -0.8999999389052391\n",
      "Run: 396, exploration: 0.007223403704104943, score: 0, Q_value: 1.004953384399414, Reward : -0.8999999389052391\n",
      "Run: 397, exploration: 0.007188093840251316, score: 0, Q_value: 0.9699746370315552, Reward : -0.299999937415123\n",
      "Run: 398, exploration: 0.007152956580136369, score: 0, Q_value: 0.9803654551506042, Reward : -0.8999999389052391\n",
      "Run: 399, exploration: 0.0071179910800284315, score: 0, Q_value: 0.933160126209259, Reward : -0.8999999389052391\n",
      "Run: 400, exploration: 0.007083196500320208, score: 0, Q_value: 0.966019332408905, Reward : -8.099999956786633\n",
      "Run: 401, exploration: 0.007048572005508617, score: 0, Q_value: 0.9344359636306763, Reward : -0.8999999389052391\n",
      "Run: 402, exploration: 0.007014116764174732, score: 0, Q_value: 0.9883387684822083, Reward : -0.8999999389052391\n",
      "Run: 403, exploration: 0.006979829948963818, score: 0, Q_value: 0.9553946256637573, Reward : -2.6999999433755875\n",
      "Run: 404, exploration: 0.006945710736565466, score: 0, Q_value: 0.9056274890899658, Reward : -0.8999999389052391\n",
      "Run: 405, exploration: 0.006911758307693816, score: 0, Q_value: 0.9481409788131714, Reward : -0.8999999389052391\n",
      "Run: 406, exploration: 0.006877971847067898, score: 0, Q_value: 0.9449006915092468, Reward : -0.8999999389052391\n",
      "Run: 407, exploration: 0.006844350543392035, score: 0, Q_value: 0.9566303491592407, Reward : -0.8999999389052391\n",
      "Run: 408, exploration: 0.0068108935893363785, score: 0, Q_value: 0.9522528648376465, Reward : -5.699999950826168\n",
      "Run: 409, exploration: 0.006777600181517517, score: 0, Q_value: 0.9514140486717224, Reward : -1.4999999403953552\n",
      "Run: 410, exploration: 0.006744469520479186, score: 0, Q_value: 0.9566108584403992, Reward : -5.699999950826168\n",
      "Run: 411, exploration: 0.006711500810673068, score: 0, Q_value: 0.9285486936569214, Reward : -5.699999950826168\n",
      "Run: 412, exploration: 0.006677357588574535, score: 0, Q_value: 0.956458568572998, Reward : -1.899999938905239\n",
      "Run: 413, exploration: 0.0066400670325340305, score: 0, Q_value: 0.8359844088554382, Reward : -1.3999999314546585\n",
      "Run: 414, exploration: 0.006607608669066885, score: 0, Q_value: 0.826659083366394, Reward : -0.8999999389052391\n",
      "Run: 415, exploration: 0.006575308970467702, score: 0, Q_value: 0.807826578617096, Reward : -0.8999999389052391\n",
      "Run: 416, exploration: 0.006542512844425488, score: 0, Q_value: 0.803493320941925, Reward : 2.2000000700354576\n",
      "Run: 417, exploration: 0.006510531351038098, score: 0, Q_value: 0.727552592754364, Reward : -0.8999999389052391\n",
      "Run: 418, exploration: 0.0064787061914544945, score: 0, Q_value: 0.745921790599823, Reward : -0.8999999389052391\n",
      "Run: 419, exploration: 0.006447036601474644, score: 0, Q_value: 0.7671898603439331, Reward : -0.8999999389052391\n",
      "Run: 420, exploration: 0.006427723510122128, score: 0, Q_value: 0.7756598591804504, Reward : 0.8000000417232513\n",
      "Run: 421, exploration: 0.006390548765971627, score: 0, Q_value: 0.6765041947364807, Reward : -1.7999999299645424\n",
      "Run: 422, exploration: 0.006359310112267665, score: 0, Q_value: 0.6669966578483582, Reward : -3.2999999448657036\n",
      "Run: 423, exploration: 0.006328224161175164, score: 0, Q_value: 0.6740500330924988, Reward : -0.8999999389052391\n",
      "Run: 424, exploration: 0.006297290166244301, score: 0, Q_value: 0.6293870806694031, Reward : -0.8999999389052391\n",
      "Run: 425, exploration: 0.006266507384674091, score: 0, Q_value: 0.6781830787658691, Reward : -0.8999999389052391\n",
      "Run: 426, exploration: 0.006235875077294555, score: 0, Q_value: 0.6505451798439026, Reward : -0.8999999389052391\n",
      "Run: 427, exploration: 0.006205392508548967, score: 0, Q_value: 0.6407454609870911, Reward : -8.099999956786633\n",
      "Run: 428, exploration: 0.006175058946476191, score: 0, Q_value: 0.6485925912857056, Reward : -8.099999956786633\n",
      "Run: 429, exploration: 0.006147332226768464, score: 0, Q_value: 0.6568329334259033, Reward : 1.100000061094761\n",
      "Run: 430, exploration: 0.0061172824783559746, score: 0, Q_value: 0.6568915843963623, Reward : -0.8999999389052391\n",
      "Run: 431, exploration: 0.00608737962087866, score: 0, Q_value: 0.6637689471244812, Reward : 1.5000000670552254\n",
      "Run: 432, exploration: 0.006057622936295676, score: 0, Q_value: 0.6548768281936646, Reward : 2.1000000685453415\n",
      "Run: 433, exploration: 0.006023793367550595, score: 0, Q_value: 0.6046621799468994, Reward : -2.5999999344348907\n",
      "Run: 434, exploration: 0.006005748166508992, score: 0, Q_value: 0.5523739457130432, Reward : 0.8000000417232513\n",
      "Run: 435, exploration: 0.005976390517568769, score: 0, Q_value: 0.5652644634246826, Reward : -0.8999999389052391\n",
      "Run: 436, exploration: 0.00594539240189909, score: 0, Q_value: 0.5381428003311157, Reward : -1.799999937415123\n",
      "Run: 437, exploration: 0.005916329787532377, score: 0, Q_value: 0.48267191648483276, Reward : -1.4999999403953552\n",
      "Run: 438, exploration: 0.005887409238734553, score: 0, Q_value: 0.4508371949195862, Reward : -0.8999999389052391\n",
      "Run: 439, exploration: 0.005867425040485716, score: 0, Q_value: 0.4681777358055115, Reward : 1.2000000476837158\n",
      "Run: 440, exploration: 0.005838743550728582, score: 0, Q_value: 0.4659719467163086, Reward : -4.499999947845936\n",
      "Run: 441, exploration: 0.0058102022635047575, score: 0, Q_value: 0.4921203553676605, Reward : -9.299999959766865\n",
      "Run: 442, exploration: 0.005792796907520585, score: 0, Q_value: 0.4887433648109436, Reward : 0.8000000417232513\n",
      "Run: 443, exploration: 0.005775443691961685, score: 0, Q_value: 0.47451141476631165, Reward : 0.8000000417232513\n",
      "Run: 444, exploration: 0.005747211830804377, score: 0, Q_value: 0.5319911241531372, Reward : -0.8999999389052391\n",
      "Run: 445, exploration: 0.005719117974279599, score: 0, Q_value: 0.4848962426185608, Reward : 2.1000000685453415\n",
      "Run: 446, exploration: 0.005691161447785046, score: 0, Q_value: 0.4955410957336426, Reward : -0.8999999389052391\n",
      "Run: 447, exploration: 0.0056633415800160436, score: 0, Q_value: 0.5230579376220703, Reward : -0.8999999389052391\n",
      "Run: 448, exploration: 0.00563565770294943, score: 0, Q_value: 0.4754565954208374, Reward : -0.8999999389052391\n",
      "Run: 449, exploration: 0.005608109151827508, score: 0, Q_value: 0.4590257406234741, Reward : -0.8999999389052391\n",
      "Run: 450, exploration: 0.005580695265142098, score: 0, Q_value: 0.5246697664260864, Reward : -0.8999999389052391\n",
      "Run: 451, exploration: 0.0055534153846186285, score: 0, Q_value: 0.4934884309768677, Reward : 0.9000000655651093\n",
      "Run: 452, exploration: 0.005523506273344381, score: 0, Q_value: 0.4807673990726471, Reward : -0.9999999329447746\n",
      "Run: 453, exploration: 0.005496505947390614, score: 0, Q_value: 0.4409763514995575, Reward : -0.8999999389052391\n",
      "Run: 454, exploration: 0.005469637606007073, score: 0, Q_value: 0.4164269268512726, Reward : -0.8999999389052391\n",
      "Run: 455, exploration: 0.0054429006040190705, score: 0, Q_value: 0.4368197023868561, Reward : -0.8999999389052391\n",
      "Run: 456, exploration: 0.005416294299405703, score: 0, Q_value: 0.42381352186203003, Reward : -0.8999999389052391\n",
      "Run: 457, exploration: 0.00538981805328443, score: 0, Q_value: 0.4275358021259308, Reward : 1.5000000670552254\n",
      "Run: 458, exploration: 0.005363471229895733, score: 0, Q_value: 0.41785314679145813, Reward : -0.8999999389052391\n",
      "Run: 459, exploration: 0.005337253196587854, score: 0, Q_value: 0.448981374502182, Reward : -0.8999999389052391\n",
      "Run: 460, exploration: 0.005311163323801594, score: 0, Q_value: 0.4276914894580841, Reward : -0.299999937415123\n",
      "Run: 461, exploration: 0.005285200985055216, score: 0, Q_value: 0.43775349855422974, Reward : -0.8999999389052391\n",
      "Run: 462, exploration: 0.005259365556929369, score: 0, Q_value: 0.432032972574234, Reward : -8.099999956786633\n",
      "Run: 463, exploration: 0.005233656419052145, score: 0, Q_value: 0.4380273222923279, Reward : 2.7000000700354576\n",
      "Run: 464, exploration: 0.005208072954084181, score: 0, Q_value: 0.4361719787120819, Reward : -0.8999999389052391\n",
      "Run: 465, exploration: 0.005182614547703823, score: 0, Q_value: 0.4448983371257782, Reward : -0.8999999389052391\n",
      "Run: 466, exploration: 0.005157280588592375, score: 0, Q_value: 0.4537496566772461, Reward : 0.30000006407499313\n",
      "Run: 467, exploration: 0.005129504946340952, score: 0, Q_value: 0.4437308609485626, Reward : 3.200000077486038\n",
      "Run: 468, exploration: 0.005104430600684638, score: 0, Q_value: 0.3951648771762848, Reward : -0.8999999389052391\n",
      "Run: 469, exploration: 0.005079478824909174, score: 0, Q_value: 0.40007948875427246, Reward : -5.099999949336052\n",
      "Run: 470, exploration: 0.005054649019861309, score: 0, Q_value: 0.3665439486503601, Reward : -8.099999956786633\n",
      "Run: 471, exploration: 0.005028934651498154, score: 0, Q_value: 0.39603668451309204, Reward : 1.7000000700354576\n",
      "Run: 472, exploration: 0.005013869703005696, score: 0, Q_value: 0.38236358761787415, Reward : 0.8000000417232513\n",
      "Run: 473, exploration: 0.004989360612299281, score: 0, Q_value: 0.32521966099739075, Reward : 1.5000000670552254\n",
      "Run: 474, exploration: 0.004964971328361454, score: 0, Q_value: 0.3394467830657959, Reward : -0.8999999389052391\n",
      "Run: 475, exploration: 0.00494070126554578, score: 0, Q_value: 0.3911151587963104, Reward : 1.5000000670552254\n",
      "Run: 476, exploration: 0.0049165498410685985, score: 0, Q_value: 0.37046554684638977, Reward : -0.8999999389052391\n",
      "Run: 477, exploration: 0.004892516474995059, score: 0, Q_value: 0.357581228017807, Reward : -3.2999999448657036\n",
      "Run: 478, exploration: 0.004868600590225176, score: 0, Q_value: 0.35250234603881836, Reward : -0.8999999389052391\n",
      "Run: 479, exploration: 0.004844801612479976, score: 0, Q_value: 0.3537532091140747, Reward : -0.8999999389052391\n",
      "Run: 480, exploration: 0.004821118970287723, score: 0, Q_value: 0.3441314697265625, Reward : -7.499999955296516\n",
      "Run: 481, exploration: 0.004797552094970162, score: 0, Q_value: 0.37084105610847473, Reward : 2.7000000700354576\n",
      "Run: 482, exploration: 0.004774100420628906, score: 0, Q_value: 0.3675052523612976, Reward : -0.8999999389052391\n",
      "Run: 483, exploration: 0.004750763384131806, score: 0, Q_value: 0.36227932572364807, Reward : 0.9000000655651093\n",
      "Run: 484, exploration: 0.004727540425099463, score: 0, Q_value: 0.3648683428764343, Reward : -0.8999999389052391\n",
      "Run: 485, exploration: 0.004704430985891752, score: 0, Q_value: 0.36458972096443176, Reward : -5.699999950826168\n",
      "Run: 486, exploration: 0.004681434511594429, score: 0, Q_value: 0.3491297960281372, Reward : 2.1000000685453415\n",
      "Run: 487, exploration: 0.004658550450005826, score: 0, Q_value: 0.3539559245109558, Reward : 0.30000006407499313\n",
      "Run: 488, exploration: 0.004635778251623576, score: 0, Q_value: 0.3629876673221588, Reward : 2.7000000700354576\n",
      "Run: 489, exploration: 0.004611272399452155, score: 0, Q_value: 0.34401723742485046, Reward : -0.4999999329447746\n",
      "Run: 490, exploration: 0.004586896091179958, score: 0, Q_value: 0.28362715244293213, Reward : -0.4999999329447746\n",
      "Run: 491, exploration: 0.004560823856290265, score: 0, Q_value: 0.1984904706478119, Reward : -1.8999999314546585\n",
      "Run: 492, exploration: 0.0045385293707509225, score: 0, Q_value: 0.1981932520866394, Reward : -2.6999999433755875\n",
      "Run: 493, exploration: 0.0045163438664178514, score: 0, Q_value: 0.1614188253879547, Reward : -0.8999999389052391\n",
      "Run: 494, exploration: 0.0044942668105627595, score: 0, Q_value: 0.18386822938919067, Reward : -0.8999999389052391\n",
      "Run: 495, exploration: 0.00447229767306146, score: 0, Q_value: 0.17719630897045135, Reward : 1.5000000670552254\n",
      "Run: 496, exploration: 0.0044504359263811575, score: 0, Q_value: 0.20131580531597137, Reward : 1.5000000670552254\n",
      "Run: 497, exploration: 0.004428681045567764, score: 0, Q_value: 0.20658159255981445, Reward : 2.1000000685453415\n",
      "Run: 498, exploration: 0.004406591804982486, score: 0, Q_value: 0.18722780048847198, Reward : -0.799999937415123\n",
      "Run: 499, exploration: 0.004385051245563934, score: 0, Q_value: 0.15801669657230377, Reward : -9.299999959766865\n",
      "Run: 500, exploration: 0.004371915149008866, score: 0, Q_value: 0.1616946905851364, Reward : 0.8000000417232513\n",
      "Run: 501, exploration: 0.00435054409804526, score: 0, Q_value: 0.14222674071788788, Reward : -0.8999999389052391\n",
      "Run: 502, exploration: 0.004329277514301101, score: 0, Q_value: 0.1865415722131729, Reward : -7.499999955296516\n",
      "Run: 503, exploration: 0.004308114887113632, score: 0, Q_value: 0.1657145470380783, Reward : -0.8999999389052391\n",
      "Run: 504, exploration: 0.004287055708316337, score: 0, Q_value: 0.1547822654247284, Reward : -8.699999958276749\n",
      "Run: 505, exploration: 0.004266099472226757, score: 0, Q_value: 0.1598060131072998, Reward : -0.8999999389052391\n",
      "Run: 506, exploration: 0.004253319714034104, score: 0, Q_value: 0.18444105982780457, Reward : 0.8000000417232513\n",
      "Run: 507, exploration: 0.004232528388202049, score: 0, Q_value: 0.15573696792125702, Reward : -0.8999999389052391\n",
      "Run: 508, exploration: 0.004209312224217326, score: 0, Q_value: 0.15575245022773743, Reward : 0.9000000730156898\n",
      "Run: 509, exploration: 0.004188736018367156, score: 0, Q_value: 0.18467603623867035, Reward : -0.8999999389052391\n",
      "Run: 510, exploration: 0.004168260394328136, score: 0, Q_value: 0.1241610199213028, Reward : -0.8999999389052391\n",
      "Run: 511, exploration: 0.0041453967516138935, score: 0, Q_value: 0.1477682739496231, Reward : -2.0999999344348907\n",
      "Run: 512, exploration: 0.0041251329811097465, score: 0, Q_value: 0.1343086212873459, Reward : -0.8999999389052391\n",
      "Run: 513, exploration: 0.00410496826515204, score: 0, Q_value: 0.13683192431926727, Reward : -0.8999999389052391\n",
      "Run: 514, exploration: 0.0040849021195365565, score: 0, Q_value: 0.09656955301761627, Reward : -0.8999999389052391\n",
      "Run: 515, exploration: 0.004064934062425989, score: 0, Q_value: 0.1233910471200943, Reward : -0.8999999389052391\n",
      "Run: 516, exploration: 0.00403980818563276, score: 1, Q_value: 0.07441400736570358, Reward : 1.3000000789761543\n",
      "Run: 517, exploration: 0.004020060559323514, score: 0, Q_value: 0.059422094374895096, Reward : -8.699999958276749\n",
      "Run: 518, exploration: 0.004000409464514511, score: 0, Q_value: 0.061742041260004044, Reward : -0.8999999389052391\n",
      "Run: 519, exploration: 0.003988425621671436, score: 0, Q_value: 0.0797095075249672, Reward : 0.8000000417232513\n",
      "Run: 520, exploration: 0.0039689291666122365, score: 0, Q_value: 0.05664603412151337, Reward : -2.6999999433755875\n",
      "Run: 521, exploration: 0.003949528015263305, score: 0, Q_value: 0.07047972083091736, Reward : -9.299999959766865\n",
      "Run: 522, exploration: 0.003930221701755479, score: 0, Q_value: 0.06401381641626358, Reward : -0.8999999389052391\n",
      "Run: 523, exploration: 0.003907491261345678, score: 0, Q_value: 0.05464329570531845, Reward : 3.0000000819563866\n",
      "Run: 524, exploration: 0.003886835311467547, score: 0, Q_value: 0.018750127404928207, Reward : -0.4999999329447746\n",
      "Run: 525, exploration: 0.0038678354560958434, score: 0, Q_value: -0.008187380619347095, Reward : -0.8999999389052391\n",
      "Run: 526, exploration: 0.0038350965552005948, score: 1, Q_value: -0.06006532907485962, Reward : -1.1999998986721039\n",
      "Run: 527, exploration: 0.0038136789688102608, score: 0, Q_value: -0.03759691119194031, Reward : -1.3999999314546585\n",
      "Run: 528, exploration: 0.0037950367205452744, score: 0, Q_value: -0.09705134481191635, Reward : 0.9000000655651093\n",
      "Run: 529, exploration: 0.003773465469131203, score: 0, Q_value: -0.06951120495796204, Reward : -2.4999999329447746\n",
      "Run: 530, exploration: 0.0037621614719886673, score: 0, Q_value: -0.08595915138721466, Reward : 0.8000000417232513\n",
      "Run: 531, exploration: 0.00374377105456041, score: 0, Q_value: -0.09321574121713638, Reward : 2.1000000685453415\n",
      "Run: 532, exploration: 0.00372547053424468, score: 0, Q_value: -0.08848823606967926, Reward : 0.30000006407499313\n",
      "Run: 533, exploration: 0.0037072594716011584, score: 0, Q_value: -0.09956672787666321, Reward : -0.8999999389052391\n",
      "Run: 534, exploration: 0.0036758797498390957, score: 1, Q_value: -0.14055873453617096, Reward : -2.9999999031424522\n",
      "Run: 535, exploration: 0.003663402358395614, score: 0, Q_value: -0.13997507095336914, Reward : 1.2000000476837158\n",
      "Run: 536, exploration: 0.0036524280722573083, score: 0, Q_value: -0.1446043848991394, Reward : 0.8000000417232513\n",
      "Run: 537, exploration: 0.003641486661283797, score: 0, Q_value: -0.13772813975811005, Reward : 0.8000000417232513\n",
      "Run: 538, exploration: 0.0036236861335129794, score: 0, Q_value: -0.14726126194000244, Reward : -5.099999949336052\n",
      "Run: 539, exploration: 0.0036059726193216133, score: 0, Q_value: -0.1133141964673996, Reward : -0.8999999389052391\n",
      "Run: 540, exploration: 0.0035854760213460167, score: 0, Q_value: -0.1301821917295456, Reward : -2.4999999329447746\n",
      "Run: 541, exploration: 0.003567949288056523, score: 0, Q_value: -0.16381482779979706, Reward : -5.699999950826168\n",
      "Run: 542, exploration: 0.0035505082299683074, score: 0, Q_value: -0.1508415788412094, Reward : 2.1000000685453415\n",
      "Run: 543, exploration: 0.0035338591647732075, score: 0, Q_value: -0.16260674595832825, Reward : 0.1000000610947609\n",
      "Run: 544, exploration: 0.0035165847480165837, score: 0, Q_value: -0.14264820516109467, Reward : -0.8999999389052391\n",
      "Run: 545, exploration: 0.003497645425590774, score: 0, Q_value: -0.1403420865535736, Reward : 0.2000000700354576\n",
      "Run: 546, exploration: 0.0034805480309490064, score: 0, Q_value: -0.18941451609134674, Reward : -0.8999999389052391\n",
      "Run: 547, exploration: 0.003461802792002656, score: 0, Q_value: -0.15687872469425201, Reward : -0.9999999329447746\n",
      "Run: 548, exploration: 0.0034448806054157045, score: 0, Q_value: -0.1599285751581192, Reward : -0.8999999389052391\n",
      "Run: 549, exploration: 0.0034270128293456825, score: 0, Q_value: -0.2018061727285385, Reward : 1.8000000715255737\n",
      "Run: 550, exploration: 0.003416746684459169, score: 0, Q_value: -0.19092902541160583, Reward : 0.8000000417232513\n",
      "Run: 551, exploration: 0.003400044743768517, score: 0, Q_value: -0.23408593237400055, Reward : 0.9000000655651093\n",
      "Run: 552, exploration: 0.003389859385936979, score: 0, Q_value: -0.18976542353630066, Reward : 0.8000000417232513\n",
      "Run: 553, exploration: 0.0033797045399139537, score: 0, Q_value: -0.23174934089183807, Reward : 0.8000000417232513\n",
      "Run: 554, exploration: 0.0033631836707976336, score: 0, Q_value: -0.20418211817741394, Reward : -0.8999999389052391\n",
      "Run: 555, exploration: 0.003352438147772786, score: 0, Q_value: -0.2207140326499939, Reward : 1.0000000447034836\n",
      "Run: 556, exploration: 0.003336050563826965, score: 0, Q_value: -0.20651347935199738, Reward : -1.4999999403953552\n",
      "Run: 557, exploration: 0.0033197430866260683, score: 0, Q_value: -0.21522022783756256, Reward : -0.8999999389052391\n",
      "Run: 558, exploration: 0.0033035153245876284, score: 0, Q_value: -0.21163734793663025, Reward : -0.8999999389052391\n",
      "Run: 559, exploration: 0.0032873668880433323, score: 0, Q_value: -0.22988739609718323, Reward : -0.8999999389052391\n",
      "Run: 560, exploration: 0.0032775190740874623, score: 0, Q_value: -0.19609875977039337, Reward : 0.8000000417232513\n",
      "Run: 561, exploration: 0.0032677007607754232, score: 0, Q_value: -0.21633556485176086, Reward : 0.8000000417232513\n",
      "Run: 562, exploration: 0.003251727395073626, score: 0, Q_value: -0.217680424451828, Reward : -0.8999999389052391\n",
      "Run: 563, exploration: 0.003241986344709468, score: 0, Q_value: -0.21084247529506683, Reward : 0.8000000417232513\n",
      "Run: 564, exploration: 0.003226138677718079, score: 0, Q_value: -0.1987168788909912, Reward : -0.8999999389052391\n",
      "Run: 565, exploration: 0.0032164742822988865, score: 0, Q_value: -0.213814377784729, Reward : 0.8000000417232513\n",
      "Run: 566, exploration: 0.0032007513248609497, score: 0, Q_value: -0.24067172408103943, Reward : -9.299999959766865\n",
      "Run: 567, exploration: 0.003185105225301826, score: 0, Q_value: -0.21010901033878326, Reward : -0.8999999389052391\n",
      "Run: 568, exploration: 0.003169535607920343, score: 0, Q_value: -0.22030475735664368, Reward : -0.8999999389052391\n",
      "Run: 569, exploration: 0.0031540420988518535, score: 0, Q_value: -0.22750331461429596, Reward : -0.8999999389052391\n",
      "Run: 570, exploration: 0.0031445936798416576, score: 0, Q_value: -0.20434527099132538, Reward : 0.8000000417232513\n",
      "Run: 571, exploration: 0.0031273450294273994, score: 0, Q_value: -0.22745029628276825, Reward : 2.700000077486038\n",
      "Run: 572, exploration: 0.0031139256471704783, score: 0, Q_value: -0.2463555932044983, Reward : 2.100000061094761\n",
      "Run: 573, exploration: 0.003097464678280166, score: 0, Q_value: -0.23799368739128113, Reward : -0.4999999329447746\n",
      "Run: 574, exploration: 0.0030823234705390896, score: 0, Q_value: -0.2839687466621399, Reward : -6.299999952316284\n",
      "Run: 575, exploration: 0.003067256276933983, score: 0, Q_value: -0.2770087420940399, Reward : 2.7000000700354576\n",
      "Run: 576, exploration: 0.0030580678382233287, score: 0, Q_value: -0.26360663771629333, Reward : 0.8000000417232513\n",
      "Run: 577, exploration: 0.003048906924896376, score: 0, Q_value: -0.24558831751346588, Reward : 0.8000000417232513\n",
      "Run: 578, exploration: 0.0030340030800013024, score: 0, Q_value: -0.24429816007614136, Reward : -0.8999999389052391\n",
      "Run: 579, exploration: 0.003017361038513336, score: 0, Q_value: -0.2728978395462036, Reward : -0.8999999314546585\n",
      "Run: 580, exploration: 0.003002311136922642, score: 0, Q_value: -0.28651413321495056, Reward : 1.0000000670552254\n",
      "Run: 581, exploration: 0.0029876350642796656, score: 0, Q_value: -0.31838101148605347, Reward : -0.8999999389052391\n",
      "Run: 582, exploration: 0.002976898378835038, score: 0, Q_value: -0.3104579448699951, Reward : 1.400000050663948\n",
      "Run: 583, exploration: 0.0029623465303203235, score: 0, Q_value: -0.2988978922367096, Reward : -8.699999958276749\n",
      "Run: 584, exploration: 0.0029534723649177566, score: 0, Q_value: -0.2966308891773224, Reward : 0.8000000417232513\n",
      "Run: 585, exploration: 0.0029390350288124177, score: 0, Q_value: -0.3179429769515991, Reward : -4.499999947845936\n",
      "Run: 586, exploration: 0.002930230696603925, score: 0, Q_value: -0.29414689540863037, Reward : 0.8000000417232513\n",
      "Run: 587, exploration: 0.002912701077377867, score: 1, Q_value: -0.3341450095176697, Reward : -0.3999999240040779\n",
      "Run: 588, exploration: 0.0028880468145499414, score: 1, Q_value: -0.3807455003261566, Reward : -2.9999999031424522\n",
      "Run: 589, exploration: 0.002873929295440948, score: 0, Q_value: -0.37864968180656433, Reward : -8.099999956786633\n",
      "Run: 590, exploration: 0.0028598807864133667, score: 0, Q_value: -0.37361422181129456, Reward : -3.2999999448657036\n",
      "Run: 591, exploration: 0.0028424877466566023, score: 1, Q_value: -0.3794603645801544, Reward : 5.400000087916851\n",
      "Run: 592, exploration: 0.002828592932044064, score: 0, Q_value: -0.3970480263233185, Reward : -0.8999999389052391\n",
      "Run: 593, exploration: 0.0028153290765378287, score: 0, Q_value: -0.3829335570335388, Reward : 0.1000000610947609\n",
      "Run: 594, exploration: 0.002806895324567175, score: 0, Q_value: -0.39122018218040466, Reward : 0.8000000417232513\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "    'eps_decay': 0.9999,\n",
    "    'eps_start': 5e-2, \n",
    "    'eps_min': 1e-5,\n",
    "    'action_space': 2,\n",
    "    'memory_size': 50000,\n",
    "    'learning_rate': 3e-6,\n",
    "    'gamma': 0.99,\n",
    "    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    'pre_train_steps': 100,\n",
    "    'num_episodes': 50000,\n",
    "    'batch_size': 48,\n",
    "    #'update_freq': 1000,\n",
    "    'img_width': 80,\n",
    "    'img_height': 80,\n",
    "    'state_size': 6400,\n",
    "    'action_size': 2,\n",
    "    'img_buffer_size': 50000\n",
    "}\n",
    "\n",
    "\n",
    "env = gymnasium.make(\"FlappyBird-v0\", render_mode='rgb_array')\n",
    "\n",
    "dql = DQNAgent(parameters=hyperparameters)\n",
    "q_values, score = dql.train(env)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
